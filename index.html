<!DOCTYPE HTML>
<html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

  <title>Shengkun Tang</title>
  
  <meta name="author" content="Shengkun Tang">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  
  <link rel="stylesheet" type="text/css" href="stylesheet.css">
  <link rel="icon" type="image/jpeg" href="images/ShengkunTang_circle.png">

	<!-- <link rel="icon" href="data:image/svg+xml,<svg xmlns=%22http://www.w3.org/2000/svg%22 viewBox=%220 0 100 100%22><text y=%22.9em%22 font-size=%2290%22>üåê</text></svg>"> -->
</head>

<!-- Google tag (gtag.js) -->
<script async src="https://www.googletagmanager.com/gtag/js?id=G-GX5X02K4TX"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'G-GX5X02K4TX');
</script>

<body>

    <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;line-height:1.4;"><tbody>
    <tr style="padding:0px">
      <td style="padding:0px">
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr style="padding:0px">
            <td style="padding:2.5%;width:63%;vertical-align:middle">
              <p style="text-align:center">
                <name>Shengkun (Bryson) Tang</name>
              </p>
              <p>Welcome to my website~ My name is Shengkun Tang. You can call me Bryson for short. 
                Currently, I am a research intern in Alibaba Qwen Team. Besides, I am a PhD student of Machine Learning in <a href="https://mbzuai.ac.ae/">MBZUAI</a>, under the supervision of <a href="https://zhiqiangshen.com/">Prof. Zhiqiang Shen</a>. 
                During my gap year, I had a wonderful time as an research assistant in <a href="https://github.com/IST-DASLab"> DASLab</a> in <a href="https://ista.ac.at/en/home/">ISTA </a>, working with <a href="https://daslab.ista.ac.at/">Prof. Dan Alistarh</a>.
                Besides, I had close collaboration with <a href="https://dongkuanx27.github.io/">Prof. Dongkuan Xu</a> (NCSU) and <a href="https://yaqingwang.github.io/">Dr. Yaqing Wang</a> (Google DeepMind), working on efficent multi-modal models.
                I finished B.E. in <a href="https://rsgis.whu.edu.cn/">Remote Sensing</a> at <a href="https://www.whu.edu.cn/">Wuhan University </a>, under the supervision of <a href="https://www.scholat.com/jianyao">Prof. Jian Yao</a> and <a href="http://jszy.whu.edu.cn/suxin1/en/index.htm">Prof. Xin Su</a>.
              </p>
              
              <p style="text-align:center">
                <a href="shengkuntangwork@gmail.com">Email</a> &nbsp/&nbsp
                <!-- <a href="data/Shengkun_Tang.pdf">CV</a> &nbsp/&nbsp -->
                <a href="https://scholar.google.com.hk/citations?user=m7ZA6vIAAAAJ&hl=zh-CN">Google Scholar</a> &nbsp/&nbsp
                <!-- <a href="https://twitter.com/CarrMichael92">Twitter</a> &nbsp/&nbsp -->
                <a href="https://github.com/Tangshengku/">Github</a>
              </p>
              <p style="text-align:right"> Last updated: June 27th 2025</p>
            </td>
            <td style="padding:2.5%;width:40%;max-width:40%">
              <a href="images/ShengkunTang_circle.png"><img style="width:100%;max-width:100%" alt="profile photo" src="images/ShengkunTang_circle.png" class="hoverZoomLink"></a>
            </td>
          </tr>
        </tbody></table>

    <div style="
      max-height: 300px;
      overflow-y: auto;
      border: 1px solid #ddd;
      padding: 16px;
      border-radius: 8px;
      background-color: #fafafa;
    ">
      <strong style="font-size: 22px;">News</strong>
      <div style="margin-top: 12px;">
        <ul style="list-style-type: none; padding-left: 0; margin: 0;">
          <li style="padding: 8px 0; border-bottom: 1px solid #eee;">
            06/2025: one paper is accepted by ICCV 2025. Congratulations to Bowei!
          </li>
          <li style="padding: 8px 0; border-bottom: 1px solid #eee;">
            06/2025: Start the research internship in Qwen pretraining team!
          </li>
          <li style="padding: 8px 0; border-bottom: 1px solid #eee;">
            04/2025: one paper is accepted by 2nd Re-Align Workshop in ICLR 2025. Congratulations to Xuanjie and Cong!
          </li>
          <li style="padding: 8px 0; border-bottom: 1px solid #eee;">
            02/2025: Happy to release the code and pretrained weights of Bi-Mamba, please check 
            <a href="https://github.com/Tangshengku/Bi-Mamba">here</a>.
          </li>
          <li style="padding: 8px 0; border-bottom: 1px solid #eee;">
            08/2024: Start my PhD life in MBZUAI.
          </li>
          <li style="padding: 8px 0; border-bottom: 1px solid #eee;">
            05/2023: Invited to serve as Reviewer for
            <a href="https://ncsu-dk-lab.github.io/workshops/relkd@2023/"><b>International Workshop on Resource-Efficient Learning for Knowledge Discovery</b></a>
            at KDD 2023.
          </li>
          <li style="padding: 8px 0; border-bottom: 1px solid #eee;">
            05/2023: Invited to give a talk at 
            <a href="http://www.thejiangmen.com/"><b>Â∞ÜÈó®ÂàõÊäï</b></a> on June 8, 2023. Welcome!
          </li>
          <li style="padding: 8px 0; border-bottom: 1px solid #eee;">
            02/2023: My first paper on 
            <strong style="color:red">accelerating inference of vision language model</strong>
            was accepted by CVPR 2023. Super excited :). Thank all co-authors' support.
          </li>
          <li style="padding: 8px 0;">
            09/2022: I joined <strong>Intelligent Automotive Group(IAG)</strong> at SenseTime as a system developer. 
            I will build system for various perception modules of self-driving.
          </li>
        </ul>
      </div>
    </div>
        <br>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <heading>Research</heading>
          <tr>
              <p>
              My research interests lie on Landable Artificial Intelligence, focusing on the <strong style="color: red;">Resource Efficiency</strong> and <strong style="color: red;">Trustworthy</strong> of <strong style="color: blue;">AI System</strong>. My research covers the whole pipeline of AI system, providing full-stack solutions from theoretical optimization methods and data-centric strategies to the development of efficient, interpretable and reliable deep learning techniques and the co-design of algorithms and hardware. 
              </p>
              <ul>
                <li><p>
                  <strong>Resource-Efficient Training & Inference Algorithms</strong>
                </p>
                <li><p>
                  <strong>Data Optimization to Improve Data Quality & Efficiency</strong>
                </p>
                <li><p>
                  <strong>Scalable Methods for AI Systems with Theoretical Guarantees</strong>
                </p>
                <li><p>
                  <strong>Algorithm-Hardware Co-design for Acceleration</strong>
                </p>
                <li><p> 
                  <strong>Application Scenario: Multi-Modal (Vision-Language), Uni-Modal (NLP, Computer Vision)</strong>
                </p>
    
                </ul>
                <strong style="color: red;">If you are interested in my research and seeking for collaboration, feel free to contact me. Any kinds of collaboration are welcome.</strong>
            </td>
          </tr>
        </tbody></table>
        <br>
        <!-- Publications -->
        <table style="width:100%; border-collapse:collapse; margin:auto;">
          <tbody>
          <heading>Publications</heading>
            <br>
            <br>
          <tr style="line-height:1.4; height:1px;">
            <td style="padding:15px; width:25%; vertical-align:top;">
              <img src="images/MosaicDiff.png" width="150">
            </td>
            <td style="padding:15px; width:75%; vertical-align:top;">
              <papertitle>MosaicDiff: Training-free Structural Pruning for Diffusion Model Acceleration Reflecting Pretraining Dynamics</papertitle><br>
              <a>Bowei Guo</a>, <strong>Shengkun Tang</strong>, <a>Cong Zeng</a>, <a>Zhiqiang Shen</a><br>
              <em><strong>[ICCV 2025]</strong></em> International Conference on Computer Vision, ICCV 2025<br>
              <a href="">Paper</a>
            </td>
          </tr>

          <tr style="line-height:1.4; height:1px;">
            <td style="padding:15px; width:25%; vertical-align:top;">
              <img src="images/number_line.png" width="150" height="100">
            </td>
            <td style="padding:15px; width:75%; vertical-align:top;">
              <papertitle>Do Large Language Models Perceive Orderly Number Concepts as Human?</papertitle><br>
              <a>Xuanjie Liu</a>, <a>Cong Zeng</a>, <strong>Shengkun Tang</strong>, <a>Ziyu Wang</a>, <a>Gus Xia</a><br>
              <em><strong>[Re-Align Workshop, ICLR 2025]</strong></em> 2nd Workshop on Representational Alignment, ICLR 2025<br>
              <a href="https://openreview.net/pdf?id=13o9GyaPFD">Paper</a>
            </td>
          </tr>

          <tr style="line-height:1.4; height:1px;">
            <td style="padding:15px; width:25%; vertical-align:top;">
              <img src="images/DALD.png" width="160">
            </td>
            <td style="padding:15px; width:75%; vertical-align:top;">
              <papertitle>DALD: Improving Logits-based Detector without Logits from Black-box LLM</papertitle><br>
              <a>Cong Zeng*</a>, <strong>Shengkun Tang*</strong>, <a>Xianjun Yang</a>, <a>Yuanzhou Chen</a>, <a>Yiyou Sun</a>, <a>Yao Li</a>, <a>Haifeng Chen</a>, <a>Wei Cheng</a>, <a>Dongkuan Xu</a><br>
              <em><strong>[NeurIPS 2024]</strong></em> The Thirty-eighth Annual Conference on Neural Information Processing Systems<br>
              <a href="https://arxiv.org/abs/2406.05232">arXiv</a> / <a href="https://github.com/cong-zeng/DALD">code</a>
            </td>
          </tr>

          <tr style="line-height:1.4; height:1px;">
            <td style="padding:15px; width:25%; vertical-align:top;">
              <img src="images/adadiff.png" width="160">
            </td>
            <td style="padding:15px; width:75%; vertical-align:top;">
              <papertitle>Adadiff: Accelerating diffusion models through step-wise adaptive computation</papertitle><br>
              <strong>Shengkun Tang</strong>, <a>Yaqing Wang</a>, <a>Caiwen Ding</a>, <a>Yi Liang</a>, <a>Yao Li</a>, <a>Dongkuan Xu</a><br>
              <em><strong>[ECCV 2024]</strong></em> European Conference on Computer Vision<br>
              <a href="https://www.ecva.net/papers/eccv_2024/papers_ECCV/papers/10120.pdf">arXiv</a> / <a href="https://github.com/Tangshengku/AdaDiff">code</a>
            </td>
          </tr>

          <tr style="line-height:1.4; height:1px;">
            <td style="padding:15px; width:25%; vertical-align:top;">
              <img src="images/MuE_Arc.jpg" width="160">
            </td>
            <td style="padding:15px; width:75%; vertical-align:top;">
              <papertitle>You Need Multiple Exiting: Dynamic Early Exiting for Accelerating Unified Vision Language Model</papertitle><br>
              <strong>Shengkun Tang</strong>, <a>Yaqing Wang</a>, <a>Zhenglun Kong</a>, <a>Tianchi Zhang</a>, <a>Yao Li</a>, <a>Caiwen Ding</a>, <a>Yanzhi Wang</a>, <a>Yi Liang</a>, <a>Dongkuan Xu</a><br>
              <em><strong>[CVPR 2023]</strong></em> The IEEE/CVF Conference on Computer Vision and Pattern Recognition<br>
              <a href="https://arxiv.org/abs/2211.11152">arXiv</a> / <a href="https://github.com/OFA-Sys/OFA/tree/feature/MuE">code</a>
            </td>
          </tr>

          <tr style="line-height:1.4; height:1px;">
            <td style="padding:15px; width:25%; vertical-align:top;">
              <img src="images/DDRNet_arc.png" width="160">
            </td>
            <td style="padding:15px; width:75%; vertical-align:top;">
              <papertitle>DDR-Net: Learning Multi-Stage Multi-View Stereo With Dynamic Depth Range</papertitle><br>
              <a>Puyuan Yi*</a>, <strong>Shengkun Tang*</strong>, <a>Jian Yao</a><br>
              <em>Preprint</em>, 2021<br>
              <a href="https://arxiv.org/abs/2103.14275">arXiv</a> / <a href="https://github.com/Tangshengku/DDR-Net">code</a>
            </td>
          </tr>

          <tr style="line-height:1.4; height:1px;">
            <td style="padding:15px; width:25%; vertical-align:top;">
              <img src="images/DSNet.png" width="160">
            </td>
            <td style="padding:15px; width:75%; vertical-align:top;">
              <papertitle>Scale-robust deep-supervision network for mapping building footprints from high-resolution remote sensing images</papertitle><br>
              <a>Haonan Guo</a>, <a>Xin Su</a>, <strong>Shengkun Tang</strong>, <a>Bo Du</a>, <a>Liangpei Zhang</a><br>
              <em>IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing</em>, 2021<br>
              <a href="https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9535260">PDF</a>
            </td>
          </tr>
          </tbody>
        </table>

        <!-- Work Experience -->
        <table style="width:100%; border-collapse:collapse; margin:auto;">
  <tbody>
    <heading>Industrial Experience</heading>  

   <tr style="line-height:1.4; height:1px;">
  <td style="padding:15px; width:25%; vertical-align:middle;">
    <img src="images/qwen-ai9316.logowik.com.webp" width="110" style="margin-top:6px;">
  </td>
  <td style="padding:15px; width:75%; vertical-align:middle;">
    <papertitle>Qwen Team, Alibaba, 06/2025 - Now</papertitle><br>
    Research Intern<br>
    Mentor: <a href="https://openreview.net/profile?id=~Bo_Zheng4">Bo Zheng</a> and <a href="https://dayihengliu.github.io/">Dayiheng Liu</a>
  </td>
</tr>

<tr style="line-height:1.4; height:1px;">
  <td style="padding:15px; width:25%; vertical-align:top;">
    <img src="images/sensetime.png" width="110" style="margin-top:12px;">
  </td>
  <td style="padding:15px; width:75%; vertical-align:top;">
    <papertitle>SenseTime, Engineering & Intelligent Automotive Group (IAG), 06/2021 - 10/2021 & 05/2022 - 07/2023</papertitle><br>
    Vision Algorithm Intern; System Developer<br>
    Project: <a href="https://www.sensetime.com/en/news-detail/51166774?categoryId=1072">SenseRobot Chess Robotic</a>, working with <a href="https://dblp.org/pid/160/6811.html">Ruodai Li</a><br>
    Project: Large-Scale Self-Driving System Development
  </td>
</tr>

  </tbody>
</table>



        <!-- Contest -->
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <heading>Contest</heading>  
          <!-- <strong><heading>Undergraduate</heading></strong> -->
          <tr onmouseout="nerfsuper_stop()" onmouseover="nerfsuper_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <br>
                <img src='images/baidu.png' width="110">
              </div>
              <script type="text/javascript">
                function nerfsuper_start() {
                  document.getElementById('nerfsuper_image').style.opacity = "1";
                }

                function nerfsuper_stop() {
                  document.getElementById('nerfsuper_image').style.opacity = "0";
                }
                nerfsuper_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://aistudio.baidu.com/aistudio/competition/detail/39/0/introduction"><papertitle>
                Baidu Astar Developer Competition,</a>
              05/2020 - 10/2020 </papertitle>
              <br>
              <br> 
              Ranking: <strong>7/2305</strong> (teams)
              <br>
              <!-- <br>          
              The task of Baidu Astar 2020 is traffic signs and surveillance cameras detection
              and matching. I was in charge of detection task. I solved the problems of data
              imbalance by using my own data argumentation strategy and detect surveil-
              lance cameras more accurately. We got into the final and rank 7 out of 2305
              teams. -->
              <br>
            </td>
          </tr>

        </tbody></table>  

        <!-- Professional Services -->
        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="0"><tbody>
          <tr>
            <td>
              <heading>Professional Services</heading>
            </td>
          </tr>
        </tbody></table>
        <table width="100%" align="center" border="0" cellpadding="5"><tbody>
          <tr>
            <td width="75%" valign="center">
              <li>
                <b>Program Committee Member:</b>
                <ul>
                  <li>NeurIPS 2024, 2025</li>
                  <li>ICCV 2025</li>
                  <li>ICML 2025</li>
                  <li>ICLR 2025</li>
                  <li>AISTATS 2025</li>
                  <li>KDD 2023, 2024</li>
                  <li>AAAI 2023</li>
                </ul>
            </td>
          </tr>
        
					
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
            <td style="padding:0px">
              <br>
              <p style="text-align:right;font-size:small;">
                This template comes from <a href="https://github.com/jonbarron/jonbarron_website">source code</a>, thanks for his fantastic website templates.
	            	
                <br>
              </p>
            </td>
          </tr>
        </tbody></table>
      </td>
    </tr>
  </table>
</body>

</html>
